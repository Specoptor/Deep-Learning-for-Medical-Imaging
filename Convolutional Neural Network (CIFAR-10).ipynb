{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gWhUHXyFIN6"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will train a convolutional neural network (CNN) on the CIFAR-10 dataset.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L61fWTwnFIOA"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/cnn/assignment.ipynb)\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAWCUP2JFIOC"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnbSpNw5FIOC"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7k4GWzNFIOC"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpakGRM1FIOD",
        "outputId": "cd2e8646-3e2c-4126-ace5-21ba13795e95"
      },
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ff/f1dd393248444d78c721d8f086a417ac0d8407892aafd8fd3e64a2088755/jarvis_md-0.0.1a12-py3-none-any.whl (74kB)\n",
            "\r\u001b[K     |████▍                           | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 30kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 40kB 23.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 51kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 61kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 71kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Collecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\r\u001b[K     |▌                               | 10kB 29.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 13.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 14.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 14.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 12.4MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 14.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a12 pyyaml-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RNUFwlRFIOD"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aA1SepQFIOD"
      },
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7vO7YN0FIOE"
      },
      "source": [
        "# Data\n",
        "\n",
        "As in the tutorial, data for this assignment will consist of the CIFAR-10 dataset comprising 10 different everyday objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset\n",
        "3. Prepare the corresponding Tensorflow Input(...) objects for model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW5_wVitFIOE",
        "outputId": "3e397366-4348-4fa4-bab5-2321768fb7b6"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='cifar')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "gen_train, gen_valid, client = datasets.prepare(name='cifar')\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-04-19 09:51:26 ] [====================] 100.000% : Iterating | 000001    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Nd4i_rFrNl"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Eo8gu5bKgPQ",
        "outputId": "e563e5da-a263-426c-80b8-7df9ee7e7f11"
      },
      "source": [
        "# --- Yield one example\n",
        "xs, ys = next(gen_train)\n",
        "\n",
        "# --- Print dict keys\n",
        "print('xs keys: {}'.format(xs.keys()))\n",
        "print('ys keys: {}'.format(ys.keys()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xs keys: dict_keys(['dat'])\n",
            "ys keys: dict_keys(['class'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlMgzefQKPq9",
        "outputId": "108f975c-29cf-40da-8cb0-90b8c4be05aa"
      },
      "source": [
        "xs, ys = next(gen_train)\n",
        "print('xs shape: {}'.format(xs['dat'].shape))\n",
        "print('ys shape: {}'.format(ys['class'].shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xs shape: (32, 32, 32, 3)\n",
            "ys shape: (32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMS8l1q_FIOE"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a basic convolutional neural network on the CIFAR-10 dataset. At minumum you must include the following baseline techniques covered in the tutorial:\n",
        "\n",
        "* convolutional operations\n",
        "* batch normalization\n",
        "* activation function\n",
        "* subsampling\n",
        "\n",
        "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vWDhsXKFIOE"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5j8MCjCFrNo"
      },
      "source": [
        "# --- Define kwargs dictionary\n",
        "kwargs = {\n",
        "    'kernel_size': (3, 3),\n",
        "    'padding': 'same'}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cFGHnG8IZ8n"
      },
      "source": [
        "# --- Define lambda functions\n",
        "conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM77o7tZFIOE"
      },
      "source": [
        "\n",
        "# --- Define stride-1, stride-2 blocks\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))\n",
        "\n",
        "l1 = conv1(16, inputs['dat'])\n",
        "l2 = conv1(24, conv2(24, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "\n",
        "f0 = layers.Flatten()(l4)\n",
        "# --- Define model\n",
        "# ...\n",
        "# ...\n",
        "\n",
        "logits = {}\n",
        "logits['class'] = layers.Dense(10, name='class')(f0)\n",
        "\n",
        "# --- Create model\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bCS0DyvFIOF"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkB2-aJkFIOF"
      },
      "source": [
        "# --- Compile model\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4), \n",
        "    loss={'class': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n",
        "    metrics={'class': 'sparse_categorical_accuracy'})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf0LJc5XFIOF"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh7QSkeGFIOF",
        "outputId": "c0d0a844-657e-45b5-de3d-ec5803fc68cd"
      },
      "source": [
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=250, \n",
        "    epochs=12,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=250,\n",
        "    validation_freq=4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "250/250 [==============================] - 39s 25ms/step - loss: 2.3203 - sparse_categorical_accuracy: 0.1796\n",
            "Epoch 2/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.7994 - sparse_categorical_accuracy: 0.3593\n",
            "Epoch 3/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.6754 - sparse_categorical_accuracy: 0.4022\n",
            "Epoch 4/12\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.5434 - sparse_categorical_accuracy: 0.4347 - val_loss: 1.5041 - val_sparse_categorical_accuracy: 0.4613\n",
            "Epoch 5/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.4900 - sparse_categorical_accuracy: 0.4695\n",
            "Epoch 6/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.4523 - sparse_categorical_accuracy: 0.4850\n",
            "Epoch 7/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.3497 - sparse_categorical_accuracy: 0.5178\n",
            "Epoch 8/12\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 1.3268 - sparse_categorical_accuracy: 0.5262 - val_loss: 1.3687 - val_sparse_categorical_accuracy: 0.5104\n",
            "Epoch 9/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.3076 - sparse_categorical_accuracy: 0.5423\n",
            "Epoch 10/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.2593 - sparse_categorical_accuracy: 0.5498\n",
            "Epoch 11/12\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 1.2613 - sparse_categorical_accuracy: 0.5472\n",
            "Epoch 12/12\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 1.2237 - sparse_categorical_accuracy: 0.5586 - val_loss: 1.2600 - val_sparse_categorical_accuracy: 0.5489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d104b6290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnqAjcR3FIOF"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37ZtVvdNFIOG",
        "outputId": "db47a64f-c374-4804-8802-947a6b021d33"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)\n",
        "\n",
        "# --- Aggregate all examples\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    xs.append(x['dat'])\n",
        "    ys.append(y['class'])\n",
        "\n",
        "xs = np.concatenate(xs)\n",
        "ys = np.concatenate(ys)\n",
        "\n",
        "# --- Predict\n",
        "logits = model.predict(xs)\n",
        "\n",
        "if type(logits) is dict:\n",
        "    logits = logits['class']\n",
        "\n",
        "# --- Argmax\n",
        "pred = np.argmax(logits, axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-04-19 09:53:54 ] [====================] 100.000% : Iterating | 012000    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8wfwa3yFrNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebff1a33-b493-4482-d32d-7c5fbc859ed0"
      },
      "source": [
        "df = pd.DataFrame(index=np.arange(pred.size))\n",
        "\n",
        "# --- Define columns\n",
        "df['true'] = ys[:, 0]\n",
        "df['pred'] = pred\n",
        "df['corr'] = df['true'] == df['pred']\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['corr'].mean())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5538333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDva0XwSFIOG"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance. It will not be graded. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NYl16vGFIOG"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n",
        "\n",
        "* true (ground-truth)\n",
        "* pred (prediction)\n",
        "* corr (correction prediction, True or False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9grLZb5iFIOG"
      },
      "source": [
        "#from google.colab import drive\n",
        "#path=drive.mount('/gdrive', force_remount=True)\n",
        "# --- Create *.csv\n",
        "\n",
        "                              \n",
        "# --- Serialize *.csv\n",
        "#fname = 'Fnaghman/models/cnn/results.csv'.format(path)\n",
        "os.makedirs(os.path.dirname('./'), exist_ok=True)\n",
        "df.to_csv('./cnn.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sn3N1bMFIOH"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8i6IT5QFIOH"
      },
      "source": [
        "model.save('./cnn.hdf5')\n",
        "\n",
        "del model\n",
        "model = models.load_model('./cnn.hdf5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjuXYDpxFIOH"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ]
}