{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxEG14n2Obgs"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will explore the building blocks required to create a contracting-expanding convolutional neural network (CNN) to perform brain tumor segmentation on MRI.\n",
        "\n",
        "This tutorial is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found at: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-m1BEoyObgx"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoE5o5uTObgy"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gylytU2nObgy"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWWPrWe4Obgy"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ghixf0OObgy",
        "outputId": "0f93dfca-48e8-42db-cdc4-b489450e7fca"
      },
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/e6/ded4e9c88d1960ab9ab8ca728348858152ad19b241b4bad8a9d5fc42e021/jarvis_md-0.0.1a13-py3-none-any.whl (81kB)\n",
            "\r\u001b[K     |████                            | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.1.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Collecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.15.0)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a13 pyyaml-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLOF1VLrObgz"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1lBfmCEObgz"
      },
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets, custom"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmYp23JCObgz"
      },
      "source": [
        "# Data\n",
        "\n",
        "The data used in this assignment will consist of brain tumor MRI exams derived from the MICCAI Brain Tumor Segmentation Challenge (BRaTS). More information about he BRaTS Challenge can be found here: http://braintumorsegmentation.org/. Each single 2D slice will consist of one of four different sequences (T2, FLAIR, T1 pre-contrast and T1 post-contrast)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxS0r1ioObg0"
      },
      "source": [
        "The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset\n",
        "3. Prepare the corresponding Tensorflow Input(...) objects for model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VhEtzMGObg0",
        "outputId": "423ebac0-4540-4087-8e52-a20868457f85"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='mr/brats-2020-mip')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "configs = {'specs': {'ys': {'tumor': {'norms': {'clip': {'max': 1}}}}}}\n",
        "gen_train, gen_valid, client = datasets.prepare(name='mr/brats-2020-mip', keyword='mip*vox', configs=configs)\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-05-04 04:50:54 ] [====================] 100.000% : Extracting archive (0000750 / 0000750) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhmvaVqNObg0"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a standard 2D U-Net for brain tumor segmentation. In addition to the baseline U-Net architecture, at minimum **one** of the following modifications must be implemented:\n",
        "\n",
        "* modification of the contracting / expanding backbone (e.g., incorporating ResNet, Inception, SENet, etc)\n",
        "* modification of the skip connection to include residual connections\n",
        "* modification of the skip connection to include additional convolution operations\n",
        "\n",
        "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHumWfVsObg0"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXYpNtC7PYYF"
      },
      "source": [
        "# --- Define kwargs dictionary\n",
        "# USE 3x3 FILTERS | BATCH NORM | ReLU | STRITED CONV\n",
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "# --- Define lambda functions\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "# --- Define stride-1, stride-2 blocks\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMCOg89nPcQQ",
        "outputId": "b6fea4f7-52d9-4b2b-93c4-db2cadf40ac8"
      },
      "source": [
        "# --- Define contracting layers\n",
        "l1 = conv1(8, inputs['dat'])\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "# --- Define single transpose\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "\n",
        "# --- Define transpose block\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))\n",
        "\n",
        "# --- Define expanding layers\n",
        "l6 = tran2(48, l5)\n",
        "\n",
        "# --- Ensure shapes match\n",
        "print(l4.shape)\n",
        "print(l6.shape)\n",
        "\n",
        "# --- Concatenate\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "concat(l4, l6)\n",
        "\n",
        "# layers for full expansion\n",
        "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
        "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
        "l9  = tran2(8,  conv1(16, concat(l2, l8)))\n",
        "l10 = conv1(8,  l9)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 30, 30, 48)\n",
            "(None, None, 30, 30, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcxbV6CtPyRF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKF9QMQBObg1"
      },
      "source": [
        "# --- Create logits\n",
        "logits = {}\n",
        "logits['tumor'] = layers.Conv3D(filters=2, name='tumor', **kwargs)(l10)\n",
        "\n",
        "# --- Create model\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMl4Sj3WObg1"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFM8jp7vObg1"
      },
      "source": [
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={'tumor': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
        "    metrics={'tumor': custom.dsc(cls=1)},\n",
        "    experimental_run_tf_function=False)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU0hOIiYH3Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef03d302-9110-41f5-d4fb-070ffd2c7fb4"
      },
      "source": [
        "# --- Load data into memory for faster training\n",
        "client.load_data_in_memory()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-05-04 04:52:01 ] [====================] 100.000% : Iterating | 000368    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkRI5vnsObg2"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEAoJRVxObg2",
        "outputId": "1537df5c-8c46-45a0-ee20-e15aada3de32"
      },
      "source": [
        "# --- Train model\n",
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=500, \n",
        "    epochs=4,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=500,\n",
        "    validation_freq=4,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "500/500 [==============================] - 115s 155ms/step - loss: 0.2838 - dsc_1: 0.3727\n",
            "Epoch 2/4\n",
            "500/500 [==============================] - 79s 158ms/step - loss: 0.0284 - dsc_1: 0.7681\n",
            "Epoch 3/4\n",
            "500/500 [==============================] - 79s 158ms/step - loss: 0.0168 - dsc_1: 0.8019\n",
            "Epoch 4/4\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0128 - dsc_1: 0.8244WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "500/500 [==============================] - 152s 303ms/step - loss: 0.0128 - dsc_1: 0.8244 - val_loss: 0.0117 - val_dsc_1: 0.8143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7fe044dbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttIdkjcCObg2"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator.\n",
        "\n",
        "The Dice score values should be calculated for the foreground class (tumor); the Dice score for background does not need to be evaluated. As discussed in the tutorial, accuracy is determined on a patient by patient (volume by volume) basis, so please calculate the Dice score values on the entire 3D volume (not slice-by-slice).\n",
        "\n",
        "### Performance\n",
        "\n",
        "The following minimum performance metrics must be met for full credit:\n",
        "\n",
        "* tumor: mean Dice score > 0.70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRGWdsktObg2",
        "outputId": "e2a1df77-aeb2-4b16-8663-ab9ac017d892"
      },
      "source": [
        "def dice(y_true, y_pred, c=1, epsilon=1):\n",
        "    \"\"\"\n",
        "    Method to calculate the Dice score coefficient for given class\n",
        "    \n",
        "    :params\n",
        "    \n",
        "      (np.ndarray) y_true : ground-truth label\n",
        "      (np.ndarray) y_pred : predicted logits scores\n",
        "      (int)             c : class to calculate DSC on\n",
        "    \n",
        "    \"\"\"\n",
        "    assert y_true.ndim == y_pred.ndim\n",
        "    \n",
        "    true = y_true[..., 0] == c\n",
        "    pred = np.argmax(y_pred, axis=-1) == c \n",
        "\n",
        "    A = np.count_nonzero(true & pred) * 2\n",
        "    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon\n",
        "    \n",
        "    return A / B\n",
        "\n",
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "x, y = next(test_train)\n",
        "logits = model.predict(x['dat'])\n",
        "\n",
        "dsc = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['tumor']\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc.append(dice(y['tumor'][0], logits[0], c=1))\n",
        "\n",
        "dsc = np.array(dsc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2021-05-04 05:00:16 ] [====================] 100.000% : Iterating | 000074    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM4XJ4AneAFe"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbrZj02AObg2"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance prior to submission. It will not be graded. Once submitted, your model will be benchmarked against the (same) validation cohort to determine final algorithm performance and grade. If your evaluation code above is correct the algorithm accuracy should match and you can confident that you will recieve full credit for the assignment. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NoAdfecObg3"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort Dice score statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that the tumor Dice score calculation column is present in the `*.csv` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTCDWXdvObg3",
        "outputId": "2f3fca0c-7b8f-4d8b-db19-469dab6f5fdb"
      },
      "source": [
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(dsc.size))\n",
        "df['Dice score'] = dsc\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['Dice score'].mean())\n",
        "# --- Create *.csv\n",
        "\n",
        "# --- Serialize *.csv\n",
        "df.to_csv('./results.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8021811757942301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SQHbPy8Obg3"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqnQoK04Obg3"
      },
      "source": [
        "# --- Serialize a model\n",
        "model.save('./segmentation.hdf5')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCHDm10QeysH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWtH4F2lObg4"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ]
}